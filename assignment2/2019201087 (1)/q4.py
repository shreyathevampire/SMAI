# -*- coding: utf-8 -*-
"""q4_temp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DP5Ks1EvoX_UcWkea8rafDfPVAbqOCZD
"""

# Commented out IPython magic to ensure Python compatibility.
'''from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive'''

import numpy as np
import pandas as pd
import math
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
#mape is left
#import seaborn as sns



"""**Check if any missing values present**

Precip Column has missing values
"""







"""Precip Type has missing values"""

class Weather:

  def __init__(self):
    data = np.empty(2)
    labels = np.empty(1)
    theta = np.empty(1)
  



  def calculate_means(self,data):
    means = [0 for row in range(len(data[0]))]
    for i in range(len(data[0])):
      values = [x[i] for x in data]
      means[i] = sum(values)/(float(len(data)))

    return means

  
  def calculate_std(self,data, means):
    stddev = [0 for row in range(len(data[0]))]
    for i in range(len(data[0])):
      values = [pow(x[i]-means[i],2) for x in data]
      stddev[i] = math.sqrt((sum(values)/ float(len(data)-1)))
    return stddev

  def standardize_data(self,data,means,stddev):
    for row in data:
      for i in range(len(data[0])):
        row[i] = (row[i] - means[i])/stddev[i]
    return data

  def fit_values(self, X, thetas, y_train, alpha, max_iterations):
    X_transposed = X
    # max_iterations = 5000
    # alpha = 0.005
    threshold = 0.0001
    for i in range(max_iterations):
      diff = np.dot(X_transposed, thetas) - y_train
      cost = sum(diff**2)
      gradient = np.dot(diff, X_transposed)
      value = (alpha*gradient)/float(len(X_transposed))
      thetas = thetas - value
    return thetas

  def predict_values(self,X):
      
      print("no of cols in test data = ", len(X[0]))
     
      y_pred = np.dot(X, self.theta)
      return y_pred

  def train(self,path):
    t_data = pd.read_csv(path)
    
    plt.matshow(t_data.corr())
    plt.show()

    cols = ['Formatted Date', 'Summary', 'Precip Type', 'Daily Summary']
    t_data = t_data.drop(cols, axis = 1)
    self.labels = t_data['Apparent Temperature (C)'].to_numpy()
    t_data = t_data.drop('Apparent Temperature (C)', axis = 1)

    
    print("heatmap")
#    ax = sns.heatmap(t_data.corr(), annot = True)
#    print(ax)
    self.data = t_data.to_numpy()
    
    split_size = int(len(self.data)*0.2)
    
    train_size = len(self.data)-split_size
    means = self.calculate_means(self.data)
    stddev = self.calculate_std(self.data,means)
    self.data = self.standardize_data(self.data,means,stddev)
    


    #add a column of ones in the input dataset
    one = np.ones(len(self.data))
    new_input = np.concatenate((one[:, np.newaxis], self.data), axis=1)
    self.data = new_input
    
    thetas = np.ones(len(new_input[0]))

    X_train = self.data[:69556,:]
    y_train =self.labels[:69556]
    X_test = self.data[69556:,:]
    y_test = self.labels[69556:]
    self.theta = self.fit_values(X_train, thetas,y_train, 0.005, 10000)
    
    y_pred = self.predict_values(X_test)
    print("predicted values")
    print(y_pred)
    print("Mean Squared Error  ",mean_squared_error(y_test, y_pred))
    print("R2 score  " ,r2_score(y_test, y_pred))
    print("Mean absolute error  ",mean_absolute_error(y_test,y_pred))
    

wr = Weather()
wr.train("/home/ubuntu/Desktop/sem2/smai/assignment2/Datasets/Question-4/weather.csv")





