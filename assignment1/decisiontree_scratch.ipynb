{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "import statistics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    treee = {}\n",
    "    data_sklearn = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self, count = 0, \n",
    "                max_depth = 2,\n",
    "                min_samples =2):\n",
    "        print(\"\")\n",
    "\n",
    "    def cal_purity_of_data(self,data):\n",
    "        label = data.iloc[:,-1]\n",
    "        count = label.unique().tolist()\n",
    "        if len(count) == 1:\n",
    "            return True\n",
    "        else :\n",
    "            return False\n",
    "        \n",
    "    def drop_columns(self,data):\n",
    "        data.drop('Id', axis=1, inplace =True)\n",
    "        data.drop('Alley', axis=1, inplace =True)\n",
    "        data.drop('PoolQC', axis=1, inplace =True)\n",
    "        data.drop('Fence', axis=1, inplace =True)\n",
    "        data.drop('MiscFeature', axis=1, inplace =True)\n",
    "        return data\n",
    "        \n",
    "        \n",
    "        \n",
    "    def handle_missing_values(self, data):\n",
    "        data = self.drop_columns(data)\n",
    "        global fill_col\n",
    "        #numerical values\n",
    "        fill_col =['YrSold','MoSold','MiscVal','PoolArea','ScreenPorch','3SsnPorch','EnclosedPorch','OpenPorchSF',\n",
    "                 'WoodDeckSF','GarageArea','GarageCars','GarageYrBlt','Fireplaces','TotRmsAbvGrd','Kitchen','Bedroom',\n",
    "                 'LotFrontage','LotArea','YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF',\n",
    "                 '1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath']\n",
    "        for i in data.columns:\n",
    "            if i in fill_col:\n",
    "                data[i].fillna(data[i].mean(), inplace =True)\n",
    "            else:\n",
    "                  data[i].fillna(data[i].mode()[0], inplace = True)\n",
    "        return fill_col,data\n",
    "        \n",
    "    def clean_data(self, data):\n",
    "        fill_col,data = self.handle_missing_values(data)\n",
    "        return fill_col,data\n",
    "    \n",
    "    def one_hot_encoding(self, data):\n",
    "        fill_col ,data = self.clean_data(data)\n",
    "        x = np.empty((data.shape[0],0),dtype='int')\n",
    "        nrows = data.shape[0]\n",
    "        col_names = data.columns\n",
    "        labelencoder = LabelEncoder()\n",
    "        for i in data.columns:\n",
    "            y = data[i]\n",
    "            if i not in fill_col:\n",
    "                labelencoder.fit(data[i])\n",
    "                encoded = labelencoder.transform(data[i])\n",
    "                one_hot = pd.DataFrame(encoded)\n",
    "                data = data.drop([i],axis=1)\n",
    "                data = pd.concat([data,one_hot],axis = 1)\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def cal_words(self,fill_col, data):\n",
    "        dictionary = []\n",
    "        for i in data.columns:\n",
    "            if ( i in fill_col or isinstance(data.iloc[0][i], str)):\n",
    "                count = data[i].unique().tolist()\n",
    "                dictionary.append(count)\n",
    "            else:\n",
    "                count = data[i].unique()\n",
    "                count = sorted(count)\n",
    "                lists = [(a+b)/2 for a,b in zip(count[::2], count[1::2])]\n",
    "                dictionary.append(lists)\n",
    "        return dictionary\n",
    "        \n",
    "    def train(self, path):\n",
    "        data_t = pd.read_csv(path)[:]\n",
    "        sklearn_t = pd.read_csv(path)\n",
    "        fill_col, data_t = self.clean_data(data_t)\n",
    "        self.data_sklearn = self.one_hot_encoding(sklearn_t)\n",
    "        dictionary_of_unique_words = self.cal_words(fill_col,data_t)\n",
    "        self.init_idx_dict(data_t.columns)\n",
    "        \n",
    "        self.treee = self.decision_tree_algo(data_t,0,3,3, dictionary_of_unique_words)\n",
    "\n",
    "    def cal_mean(self,data):\n",
    "        answer = 0\n",
    "        if len(data) == 0:\n",
    "            return answer\n",
    "        else :\n",
    "            answer = np.mean(data)\n",
    "        return answer\n",
    "    \n",
    "\n",
    "    def split_data(self,data, column, split_at_value, mask = 1):\n",
    "\n",
    "        if mask == 1:\n",
    "            data_below_value = data[data.iloc[:,column] <= split_at_value]\n",
    "            data_above_value = data[data.iloc[:,column] > split_at_value]\n",
    "            return data_below_value, data_above_value\n",
    "        else:\n",
    "            data_below_value = data[data.iloc[:,column] == split_at_value]\n",
    "            data_above_value = data[data.iloc[:,column] != split_at_value]\n",
    "        return data_below_value, data_above_value\n",
    "    \n",
    "    def cal_mse(self,data):\n",
    "        res= 0\n",
    "        label_values = (data.iloc[:,-1]).tolist()\n",
    "        if len(label_values) == 0:\n",
    "            return 0\n",
    "        avg = statistics.mean(label_values)\n",
    "        sum = 0\n",
    "        for i in range(len(label_values)):\n",
    "            sum += (label_values[i] - avg)**2\n",
    "        res = sum/len(label_values) \n",
    "        return res\n",
    "    \n",
    "    \n",
    "    def cal_entropy_at_each_split(self,data,feature, value_at_feature):\n",
    "        total_length = data.shape[0]\n",
    "        if index_dictionary[feature] not in fill_col:\n",
    "            data_below_value, data_above_value = self.split_data(data,feature,value_at_feature, 0)\n",
    "        else:\n",
    "            data_below_value, data_above_value = self.split_data(data,feature,value_at_feature, 1)\n",
    "        prob = 0\n",
    "        prob += (len(data_below_value)/total_length)*self.cal_mse(data_below_value)\n",
    "        prob += (len(data_above_value)/total_length)*self.cal_mse(data_above_value)\n",
    "        return prob,(data_below_value, data_above_value)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    def cal_entropy(self,data,dictionary):\n",
    "        values_of_each_row = []\n",
    "        for i in range(len(dictionary)-1):\n",
    "            flag = True\n",
    "            row = dictionary[i]\n",
    "            mse_at_each_split = []\n",
    "            for j in range(len(row)):\n",
    "                temp_data = data\n",
    "                entropy_at_each_split = self.cal_entropy_at_each_split(temp_data,i,row[j])[0]\n",
    "                if flag == True or entropy_at_each_split < min_entropy :\n",
    "                    min_entropy = entropy_at_each_split\n",
    "                    feature = i\n",
    "                    value_at_feature = row[j]\n",
    "                    flag = False\n",
    "            values_of_each_row.append((min_entropy,feature,value_at_feature))\n",
    "        return min(values_of_each_row)[1], min(values_of_each_row)[2]\n",
    "  \n",
    "    \n",
    "    def init_idx_dict(self, list_of_columns):\n",
    "        global index_dictionary\n",
    "        index_dictionary={}\n",
    "        for i in range(len(list_of_columns)):\n",
    "            index_dictionary[i] = list_of_columns[i]\n",
    "            \n",
    "\n",
    "    def decision_tree_algo(self,data, count, max_depth , min_samples , dictionary):\n",
    "\n",
    "        rows = data.shape[0]\n",
    "        if self.cal_purity_of_data(data) or rows <= min_samples or count == max_depth :\n",
    "            lists = data.iloc[:,-1].tolist()\n",
    "            answer = self.cal_mean(lists)\n",
    "            return answer\n",
    "        count = count + 1\n",
    "        col_no, value_for_split = self.cal_entropy(data,dictionary)\n",
    "        values = self.cal_entropy_at_each_split(data, col_no, value_for_split)[1]\n",
    "        data_below_value = values[0]\n",
    "        data_above_value = values[1]\n",
    "        '''instantiate subtree'''\n",
    "        list_of_columns = data.columns\n",
    "        \n",
    "        if index_dictionary[col_no] not in fill_col:\n",
    "\n",
    "            question_to_ask = \"{} == {}\".format(col_no,value_for_split)\n",
    "        else:\n",
    "\n",
    "            question_to_ask = \"{} <= {}\".format(col_no, value_for_split)\n",
    "\n",
    "        sub_tree = {question_to_ask : []}\n",
    "        true_value = self.decision_tree_algo(data_below_value,count,max_depth,min_samples,dictionary)\n",
    "\n",
    "        false_value = self.decision_tree_algo(data_above_value, count, max_depth, min_samples, dictionary)\n",
    "\n",
    "        if true_value == false_value:\n",
    "            sub_tree[question_to_ask].append(true_value)\n",
    "        else:\n",
    "            sub_tree[question_to_ask].append(true_value)\n",
    "            sub_tree[question_to_ask].append(false_value)\n",
    "\n",
    "        return sub_tree\n",
    "\n",
    "    def testing_values(self,treee,test_data_point ):\n",
    "\n",
    "        questions = list(self.treee.keys())[0]\n",
    "        column_no, comparison_op, value_at_split = questions.split(' ')\n",
    "\n",
    "        var = int(column_no)\n",
    "        if comparison_op == \"<=\": #numerical data\n",
    "\n",
    "            if test_data_point[var] <= float(value_at_split):\n",
    "                solution = self.treee[questions][0]\n",
    "            else : \n",
    "                solution = self.treee[questions][1]\n",
    "        else: #categorical \n",
    "            if test_data_point[var] == value_at_split:\n",
    "                solution = self.treee[questions][0]\n",
    "            else : \n",
    "                solution = self.treee[questions][1]\n",
    "                \n",
    "        if not isinstance(solution,dict):\n",
    "            return solution\n",
    "        else:\n",
    "            self.treee = solution\n",
    "        return self.testing_values(self.treee, test_data_point)\n",
    "\n",
    "    def predict(self, test_data_path):\n",
    "        \n",
    "\n",
    "        y_pred = []\n",
    "        test_data = pd.read_csv(test_data_path)\n",
    "        sklearn_test_data = pd.read_csv(test_data_path)\n",
    "        \n",
    "        \n",
    "        fill_col, test_data = self.clean_data(test_data)\n",
    "\n",
    "        test_data=test_data.iloc[:10,:]\n",
    "\n",
    "        for i in range(test_data.shape[0]):\n",
    "\n",
    "\n",
    "            test_data_point = test_data.iloc[i,:].to_numpy()\n",
    "\n",
    "            y_pred.append(self.testing_values(self.treee,test_data_point))\n",
    "    \n",
    "\n",
    "        train_data = self.data_sklearn.iloc[:,:-1].values\n",
    "        train_values = self.data_sklearn.iloc[:,-1].values\n",
    "        test_data = self.one_hot_encoding(sklearn_test_data)\n",
    "        regressor = DecisionTreeRegressor(random_state = 0)\n",
    "        regressor.fit(train_data, train_values)\n",
    "        predicted = regressor.predict(test_data)\n",
    "        return y_pred,predicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Metric\n",
      "mse: 774907067.1161859\n",
      "mae: 22406.751019955653\n",
      "\n",
      "Scikit learn Metric \n",
      "mse: 25268796402.2\n",
      "mae: 153907.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    dtr = DecisionTree()\n",
    "    dtr.train(\"/home/ubuntu/Desktop/smai/Datasets/q3/train.csv\")\n",
    "    predictions,classifier_pred = dtr.predict(\"/home/ubuntu/Desktop/smai/Datasets/q3/test.csv\")\n",
    "    test_labels = list()\n",
    "    with open(\"/home/ubuntu/Desktop/smai/Datasets/q3/test_labels.csv\") as f:\n",
    "        for line in f:\n",
    "            test_labels.append(float(line.split(',')[1]))\n",
    "\n",
    "\n",
    "    print(\"Decision Tree Metric\")\n",
    "    print (\"mse:\", mean_squared_error(test_labels[:10], predictions[:10]))\n",
    "    print (\"mae:\", mean_absolute_error(test_labels[:10], predictions[:10]))\n",
    "    \n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Scikit learn Metric \")\n",
    "\n",
    "    print (\"mse:\", mean_squared_error(test_labels[:10], classifier_pred[:10]))\n",
    "    print (\"mae:\", mean_absolute_error(test_labels[:10], classifier_pred[:10]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
